{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "random.seed(25)\n",
    "\n",
    "SUP_DATA = './features_sup/clustering_outputs.torch'\n",
    "OUTPUT_PATH = './imagenet_{}_intra_{}_inter_{}.json'\n",
    "LT_DIST_PATH = './long-tail-distribution.pytorch' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the label of clusters in a decreasing order\n",
    "def cluster_ranking(cls_data):\n",
    "    new_data = {}\n",
    "    idx2label = {}\n",
    "    label_num = []\n",
    "    count_img = 0\n",
    "    for key, val in cls_data.items():\n",
    "        num_cat_img = sum([len(item) for item in val.values()])\n",
    "        label_num.append((key, num_cat_img))\n",
    "        count_img += num_cat_img\n",
    "        cluster_paths = list(val.values())\n",
    "        cluster_paths.sort(key=len, reverse=True)\n",
    "        new_data[key] = {i : [] for i in range(3)}\n",
    "        for i, paths in enumerate(cluster_paths):\n",
    "            new_data[key][i//2] += paths\n",
    "    # sort category by the number of images\n",
    "    sorted_labels = sorted(label_num, reverse=True, key=lambda item: item[1])\n",
    "    # sorted labels\n",
    "    for i, item in enumerate(sorted_labels):\n",
    "        idx2label[str(i)] = item[0]\n",
    "        \n",
    "    new_data = {str(i) : new_data[idx2label[str(i)]] for i in range(len(idx2label))}\n",
    "    print('===== Total Number of Images is {} ====='.format(count_img))\n",
    "    return new_data, idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_test(cls_data, VAL_SIZE=10, TEST_SIZE=20, NUM_CAT=1000, NUM_ATT=3, intra_type='lt', inter_type='bl'):\n",
    "    trainset =         {'label':{}, 'frequency':{}, 'attribute':{}}\n",
    "    valset =           {'label':{}, 'frequency':{}, 'attribute':{}}\n",
    "    testset_lt =       {'label':{}, 'frequency':{}, 'attribute':{}}\n",
    "    testset_bl =       {'label':{}, 'frequency':{}, 'attribute':{}}\n",
    "    testset_bbl =      {'label':{}, 'frequency':{}, 'attribute':{}}\n",
    "    \n",
    "    # intra distribution\n",
    "    intra_dist = [7,2,1]\n",
    "    print('Intra-Distribution is ' + str(intra_dist))\n",
    "    print_total_img(cls_data)\n",
    "    \n",
    "    #################################################\n",
    "    # TEST BBL: generate test set that has the balanced\n",
    "    # distribution for both category and attribute\n",
    "    #################################################\n",
    "    cls_data, testset_bbl =  generate_balanced_test(cls_data, testset_bbl, TEST_SIZE)\n",
    "    print_total_img(cls_data)\n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    # TEST BL: generate test set that only has the balanced\n",
    "    # class distribution\n",
    "    #################################################\n",
    "    if intra_type == 'lt' and inter_type == 'lt':\n",
    "        cls_data, testset_bl = generate_intra_lt_test(cls_data, testset_bl, intra_dist, TEST_SIZE, NUM_ATT)\n",
    "    elif intra_type == 'lt' and inter_type == 'bl':\n",
    "        cls_data, testset_bl = generate_intra_lt_test(cls_data, testset_bl, intra_dist, TEST_SIZE, NUM_ATT)\n",
    "    else:\n",
    "        raise ValueError('Wrong Combination of Distribution Types')\n",
    "    print_total_img(cls_data)\n",
    "    \n",
    "\n",
    "    #################################################\n",
    "    # Generate Imbalanced Dataset\n",
    "    #################################################\n",
    "    if intra_type == 'lt' and inter_type == 'lt':\n",
    "        cls_data = get_long_tailed_data(cls_data, intra_dist, imb_type='predefined')\n",
    "    elif intra_type == 'lt' and inter_type == 'bl':\n",
    "        cls_data = get_long_tailed_data(cls_data, intra_dist, imb_type='bl')\n",
    "    else:\n",
    "        raise ValueError('Wrong Combination of Distribution Types')\n",
    "    print_total_img(cls_data)\n",
    "    \n",
    "        \n",
    "    #################################################\n",
    "    # TEST LT: generate test set that has the same\n",
    "    # distribution with long-tailed train set\n",
    "    #################################################\n",
    "    if intra_type == 'lt' and inter_type == 'lt':\n",
    "        cls_data, testset_lt = generate_iid_set(cls_data, testset_lt, TEST_SIZE, NUM_ATT)\n",
    "    print_total_img(cls_data)\n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    # VAL: generate validation set, the distribution \n",
    "    # of val set should be the same as train set\n",
    "    #################################################\n",
    "    if intra_type == 'lt' and inter_type == 'lt':\n",
    "        cls_data, valset = generate_iid_set(cls_data, valset, VAL_SIZE, NUM_ATT)\n",
    "    elif intra_type == 'lt' and inter_type == 'bl':\n",
    "        cls_data, valset = generate_intra_lt_test(cls_data, valset, intra_dist, VAL_SIZE, NUM_ATT)\n",
    "    else:\n",
    "        raise ValueError('Wrong Combination of Distribution Types')\n",
    "    print_total_img(cls_data)\n",
    "        \n",
    "        \n",
    "    #################################################\n",
    "    # TRAIN\n",
    "    #################################################\n",
    "    for key, val in cls_data.items():\n",
    "        for c_key, c_val in val.items():\n",
    "            for item in c_val:\n",
    "                trainset['label'][item] = key\n",
    "                trainset['frequency'][item] = get_frequency_label(key)\n",
    "                trainset['attribute'][item] = c_key\n",
    "    print('====== Total Num of Train Set is {} ========'.format(len(trainset['label'])))\n",
    "    \n",
    "    return trainset, valset, testset_lt, testset_bl, testset_bbl\n",
    "        \n",
    "\n",
    "def get_frequency_label(input_label):\n",
    "    if int(input_label) < 400:\n",
    "        return 0\n",
    "    elif int(input_label) < 850:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "    \n",
    "def get_long_tailed_data(cls_data, intra_dist, imb_type='exp', imb_factor=0.05, print_table=True):\n",
    "    # get long_tailed category list\n",
    "    img_max = 1800\n",
    "    cls_sizes = [sum([len(c_val) for c_key, c_val in val.items()]) for key, val in cls_data.items()]\n",
    "    cls_num = len(cls_sizes)\n",
    "    img_num_per_cls = []\n",
    "\n",
    "    if imb_type == 'predefined':\n",
    "        lt_dist = torch.load(LT_DIST_PATH)\n",
    "        # check validity\n",
    "        for i in range(len(lt_dist) - 1):\n",
    "            assert lt_dist[i] >= lt_dist[i+1]\n",
    "        # set distribution\n",
    "        img_num_per_cls = lt_dist\n",
    "    elif imb_type == 'exp':\n",
    "        for cls_idx in range(cls_num):\n",
    "            num = img_max * (imb_factor**(cls_idx / (cls_num - 1.0)))\n",
    "            img_num_per_cls.append(min(int(num), cls_sizes[cls_idx]))\n",
    "    elif imb_type == 'step':\n",
    "        for cls_idx in range(cls_num):\n",
    "            if cls_idx < int(cls_num * 0.2):\n",
    "                img_num_per_cls.append(cls_sizes[cls_idx])\n",
    "            elif cls_idx < int(cls_num * 0.4):\n",
    "                img_num_per_cls.append(min(cls_sizes[cls_idx], img_max * 0.5))\n",
    "            else:\n",
    "                img_num_per_cls.append(min(cls_sizes[cls_idx], img_max * 0.05))\n",
    "    elif imb_type == 'bl':\n",
    "        for cls_idx in range(cls_num):\n",
    "            img_num_per_cls.append(min(145, cls_sizes[cls_idx]))\n",
    "    else:\n",
    "        raise ValueError('Wrong Type')\n",
    "        \n",
    "    if print_table:\n",
    "        show_statistics(img_num_per_cls)\n",
    "    \n",
    "    # sampling long-tailed dataset\n",
    "    att_dist = torch.FloatTensor(intra_dist)\n",
    "    \n",
    "    for cls_idx, (key, val) in enumerate(cls_data.items()):\n",
    "        num_imgs = img_num_per_cls[cls_idx]\n",
    "        num_atts = ((att_dist / att_dist.sum()) * num_imgs).long().tolist()\n",
    " \n",
    "        for att_idx, (c_key, c_val) in enumerate(val.items()):\n",
    "            att_len = min(num_atts[att_idx], len(c_val))\n",
    "            del c_val[att_len:]\n",
    "    \n",
    "    return cls_data\n",
    "\n",
    "def generate_balanced_test(cls_data, input_set, VAL_SIZE):\n",
    "    # both attribute and category are balanced\n",
    "    for key, val in cls_data.items():\n",
    "        # get the size for each attribute cluster\n",
    "        att_size = VAL_SIZE\n",
    "        for c_key, c_val in val.items():\n",
    "            att_size = min(att_size, len(c_val)//4)\n",
    "        \n",
    "        # update inputset\n",
    "        for c_key, c_val in val.items():\n",
    "            for _ in range(att_size):\n",
    "                item = c_val.pop(0)\n",
    "                input_set['label'][item] = key\n",
    "                input_set['frequency'][item] = get_frequency_label(key)\n",
    "                input_set['attribute'][item] = c_key\n",
    "    \n",
    "    print('====== Total Num of Both Balanced Test Set is {} ========'.format(len(input_set['label'])))\n",
    "    return cls_data, input_set\n",
    "\n",
    "\n",
    "def generate_intra_lt_test(cls_data, input_set, intra_dist, VAL_SIZE, NUM_ATT):\n",
    "    # attribute is iid\n",
    "    # category is balanced\n",
    "    TOTAL_SIZE = VAL_SIZE * NUM_ATT\n",
    "    multi_weight = int(TOTAL_SIZE / sum(intra_dist))\n",
    "    \n",
    "    for key, val in cls_data.items():\n",
    "        for i, (c_key, c_val) in enumerate(val.items()):\n",
    "            att_size = intra_dist[i] * multi_weight\n",
    "            for _ in range(att_size):\n",
    "                item = c_val.pop(0)\n",
    "                input_set['label'][item] = key\n",
    "                input_set['frequency'][item] = get_frequency_label(key)\n",
    "                input_set['attribute'][item] = c_key\n",
    "    \n",
    "    print('====== Total Num of Half Balanced Test Set is {} ========'.format(len(input_set['label'])))\n",
    "    return cls_data, input_set\n",
    "\n",
    "\n",
    "def generate_iid_set(cls_data, input_set, VAL_SIZE, NUM_ATT):\n",
    "    # attribute is long-tailed (iid)\n",
    "    # category is long-tailed (iid)\n",
    "    num_cls = len(cls_data)\n",
    "    TOTAL_SIZE = num_cls * VAL_SIZE * NUM_ATT\n",
    "    \n",
    "    container = []\n",
    "    for key, val in cls_data.items():\n",
    "        for c_key, c_val in val.items():\n",
    "            for item in c_val:\n",
    "                container.append( ((key, c_key), item) )\n",
    "    \n",
    "    # update inputset\n",
    "    for i in range(TOTAL_SIZE):\n",
    "        idx = random.randint(0, len(container)-1)\n",
    "        item = container.pop(idx)\n",
    "        key = item[0][0]\n",
    "        c_key = item[0][1]\n",
    "        c_val = item[1]\n",
    "        input_set['label'][c_val] = key\n",
    "        input_set['frequency'][c_val] = get_frequency_label(key)\n",
    "        input_set['attribute'][c_val] = c_key\n",
    "        \n",
    "    # update new_cls_data\n",
    "    new_cls_data = {}\n",
    "    for key, val in cls_data.items():\n",
    "        new_cls_data[key] = {i:[] for i in range(NUM_ATT)}\n",
    "    for item in container:\n",
    "        key = item[0][0]\n",
    "        c_key = item[0][1]\n",
    "        c_val = item[1]\n",
    "        new_cls_data[key][c_key].append(c_val)\n",
    "    \n",
    "    print('====== Total Num of IID Set is {} ========'.format(len(input_set['label'])))\n",
    "    return new_cls_data, input_set\n",
    "    \n",
    "def print_total_img(cls_data):\n",
    "    count = 0\n",
    "    for key, val in cls_data.items():\n",
    "        for c_key, c_val in val.items():\n",
    "            count += len(c_val)\n",
    "    print('NOTE: The current size of remaining data is {}'.format(count))\n",
    "    \n",
    "def show_statistics(vals):\n",
    "    # sort your values in descending order\n",
    "    indSort = np.argsort(vals)[::-1]\n",
    "    # rearrange your data\n",
    "    att_values = np.array(vals)[indSort]\n",
    "    indexes = np.arange(len(vals))\n",
    "    bar_width = 0.35\n",
    "    plt.bar(indexes, att_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output():\n",
    "    output_dict = {}\n",
    "    \n",
    "    id2cat = idx2label\n",
    "    cat2id = {cat:i for i, cat in id2cat.items()}\n",
    "   \n",
    "    output_dict['cat2id'] = cat2id\n",
    "    output_dict['id2cat'] = id2cat\n",
    "    output_dict['train'] = trainset\n",
    "    output_dict['val'] = valset\n",
    "    output_dict['test_lt'] = testset_lt\n",
    "    output_dict['test_bl'] = testset_bl\n",
    "    output_dict['test_bbl'] = testset_bbl\n",
    "    \n",
    "    with open(OUTPUT_PATH.format(feature_type, intra_type, inter_type), 'w') as outfile:\n",
    "        json.dump(output_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Total Number of Images is 1281167 =====\n",
      "Intra-Distribution is [7, 2, 1]\n",
      "NOTE: The current size of remaining data is 1281167\n",
      "====== Total Num of Both Balanced Test Set is 60000 ========\n",
      "NOTE: The current size of remaining data is 1221167\n",
      "====== Total Num of Half Balanced Test Set is 60000 ========\n",
      "NOTE: The current size of remaining data is 1161167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: The current size of remaining data is 144000\n",
      "NOTE: The current size of remaining data is 144000\n",
      "====== Total Num of Half Balanced Test Set is 30000 ========\n",
      "NOTE: The current size of remaining data is 114000\n",
      "====== Total Num of Train Set is 114000 ========\n"
     ]
    }
   ],
   "source": [
    "# get clustering data\n",
    "feature_type = 'sup'\n",
    "intra_type = 'lt'\n",
    "inter_type = 'bl'\n",
    "\n",
    "cls_data = torch.load(SUP_DATA)\n",
    "cls_data, idx2label = cluster_ranking(cls_data)\n",
    "\n",
    "# generate data\n",
    "trainset, valset, testset_lt, testset_bl, testset_bbl = generate_train_val_test(cls_data, intra_type=intra_type, inter_type=inter_type)\n",
    "save_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Total Number of Images is 1281167 =====\n",
      "Intra-Distribution is [7, 2, 1]\n",
      "NOTE: The current size of remaining data is 1281167\n",
      "====== Total Num of Both Balanced Test Set is 60000 ========\n",
      "NOTE: The current size of remaining data is 1221167\n",
      "====== Total Num of Half Balanced Test Set is 60000 ========\n",
      "NOTE: The current size of remaining data is 1161167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: The current size of remaining data is 203460\n",
      "====== Total Num of IID Set is 60000 ========\n",
      "NOTE: The current size of remaining data is 143460\n",
      "====== Total Num of IID Set is 30000 ========\n",
      "NOTE: The current size of remaining data is 113460\n",
      "====== Total Num of Train Set is 113460 ========\n"
     ]
    }
   ],
   "source": [
    "# get clustering data\n",
    "feature_type = 'sup'\n",
    "intra_type = 'lt'\n",
    "inter_type = 'lt'\n",
    "\n",
    "cls_data = torch.load(SUP_DATA)\n",
    "cls_data, idx2label = cluster_ranking(cls_data)\n",
    "\n",
    "# generate data\n",
    "trainset, valset, testset_lt, testset_bl, testset_bbl = generate_train_val_test(cls_data, intra_type=intra_type, inter_type=inter_type)\n",
    "save_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
