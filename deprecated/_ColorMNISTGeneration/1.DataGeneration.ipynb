{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5db594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import requests\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import feature as skif\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "74f34318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorMNIST_LT(torchvision.datasets.MNIST):\n",
    "    def __init__(self, phase, test_type, output_path, logger, cat_ratio=1.0, att_ratio=0.1):\n",
    "        super(ColorMNIST_LT, self).__init__(root='./', train=(phase == 'train'), download=True)\n",
    "        # mnist dataset contains self.data, self.targets\n",
    "        self.dig2label = {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 2, 8: 2, 9: 2}\n",
    "        self.dig2attri = {}\n",
    "        self.colors = {0:[1,0,0], 1:[0,1,0], 2:[0,0,1]}\n",
    "        \n",
    "        self.cat_ratio = cat_ratio\n",
    "        self.att_ratio = att_ratio\n",
    "        # generate long-tailed data\n",
    "        self.generate_lt_label(cat_ratio)\n",
    "        \n",
    "        \n",
    "    def generate_lt_label(self, ratio=1.0):\n",
    "        self.label2list = {i:[] for i in range(3)}\n",
    "        for img, dig in zip(self.data, self.targets):\n",
    "            label = self.dig2label[int(dig)]\n",
    "            self.label2list[label].append(img)\n",
    "        if ratio == 1.0:\n",
    "            balance_size = min([len(val) for key, val in self.label2list.items()])\n",
    "            for key, val in self.label2list.items():\n",
    "                self.label2list[key] = val[:balance_size]\n",
    "        elif ratio < 1.0:\n",
    "            current_size = len(self.label2list[0])\n",
    "            for key, val in self.label2list.items():\n",
    "                max_size = len(val)\n",
    "                self.label2list[key] = val[:min(max_size, current_size)]\n",
    "                current_size = int(current_size * ratio)\n",
    "        else:\n",
    "            raise ValueError('Wrong Ratio in ColorMNIST')\n",
    "        \n",
    "        self.lt_labels = []\n",
    "        self.lt_imgs = []\n",
    "        for key, val in self.label2list.items():\n",
    "            for item in val:\n",
    "                self.lt_labels.append(key)\n",
    "                self.lt_imgs.append(item)\n",
    "            print('Generate ColorMNIST: label {} has {} images.'.format(key, len(val)))\n",
    "        \n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.lt_labels)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.lt_imgs[index].unsqueeze(-1).repeat(1,1,3)\n",
    "        label = self.lt_labels[index]\n",
    "        \n",
    "        # generate tail colors\n",
    "        if random.random() < self.att_ratio:\n",
    "            att_label = random.randint(0,2)\n",
    "            color = self.colors[att_label]\n",
    "        else:\n",
    "            color = self.colors[label]\n",
    "        \n",
    "        # assign attribute\n",
    "        img = self.to_color(img, color)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "    def to_color(self, img, rgb=[1,0,0]):\n",
    "        return (img * torch.FloatTensor(rgb).unsqueeze(0).unsqueeze(0)).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0bddd1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(input_tensor):\n",
    "    return Image.fromarray(input_tensor.numpy()).resize((64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "77a12b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate ColorMNIST: label 0 has 24754 images.\n",
      "Generate ColorMNIST: label 1 has 2475 images.\n",
      "Generate ColorMNIST: label 2 has 247 images.\n"
     ]
    }
   ],
   "source": [
    "dataset = ColorMNIST_LT('train', 'test_iid', '.', None, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "72d73ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FE130211438>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualization(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1a89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f89360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f415f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
